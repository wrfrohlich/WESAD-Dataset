{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Deep Learning - CNN-RNN - TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WESAD\n",
    "start_participant = 2\n",
    "final_participant = 17\n",
    "\n",
    "number_of_classes = 2\n",
    "\n",
    "path = 'WESAD'\n",
    "\n",
    "if (number_of_classes == 2):\n",
    "    # Amount of Data\n",
    "    size_line = 240\n",
    "\n",
    "    size_column_train = 100\n",
    "    size_column_test = 32\n",
    "    \n",
    "    # Matrix Dimension\n",
    "    width = 10          #n\n",
    "    height = 24        #m\n",
    "    channel = 35         #c\n",
    "\n",
    "elif (number_of_classes == 4):\n",
    "    # Amount of Data\n",
    "    size_line = 360\n",
    "    \n",
    "    size_column_train = 100\n",
    "    size_column_test = 35\n",
    "    \n",
    "    # Matrix Dimension\n",
    "    width = 10          #n\n",
    "    height = 36        #m\n",
    "    channel = 35         #c\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 50\n",
    "\n",
    "# Image Format\n",
    "image_size = (width, height, channel)\n",
    "\n",
    "#Epochs\n",
    "epochs = 1000\n",
    "\n",
    "#Optimizer\n",
    "optimizer = \"rmsprop\"\n",
    "\n",
    "#Activation\n",
    "activation = \"softmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, Conv2D, MaxPooling2D, Flatten, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, auc ,precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy.fft as fft\n",
    "from scipy.signal import find_peaks,peak_widths\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Functions and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df,classes):\n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for i in range(int(len(df)/700)):\n",
    "        x = df.iloc[i:i+int(len(df)/700),:]\n",
    "        mn_acc_x = x['ACC_X'].mean()\n",
    "        mn_acc_y = x['ACC_Y'].mean()\n",
    "        mn_acc_z = x['ACC_Z'].mean()\n",
    "        std_acc_x = x['ACC_X'].std()\n",
    "        std_acc_y = x['ACC_Y'].std()\n",
    "        std_acc_z = x['ACC_Z'].std()\n",
    "        itgl_acc_x = np.trapz(x['ACC_X'])\n",
    "        itgl_acc_y = np.trapz(x['ACC_Y'])\n",
    "        itgl_acc_z = np.trapz(x['ACC_Z'])\n",
    "        mn_emg = x['EMG'].mean()\n",
    "        std_emg = x['EMG'].std()\n",
    "        max_emg = np.amax(x['ACC_X'])\n",
    "        min_emg = np.amin(x['ACC_X']) \n",
    "        dr_emg = max_emg/min_emg\n",
    "        #rint(dr_emg)\n",
    "        itgl_emg = np.trapz(x['EMG'])\n",
    "        med_emg = np.median(x['EMG'])\n",
    "        per_10_emg = np.percentile(x['EMG'],10)\n",
    "        per_90_emg = np.percentile(x['EMG'],90)\n",
    "        peaks,properties = find_peaks(x['EMG'],height = 0)\n",
    "        mn_pk_amp = np.mean(properties['peak_heights'])\n",
    "        std_pk_amp = np.std(properties['peak_heights'])\n",
    "        sum_pk_amp = np.sum(properties['peak_heights'])\n",
    "        mn_temp = x['TEMP'].mean()\n",
    "        std_temp = x['TEMP'].std()\n",
    "        max_temp = x['TEMP'].max()\n",
    "        min_temp = x['TEMP'].min()\n",
    "        dr_temp = max_temp/min_temp\n",
    "        mn_eda = x['EDA'].mean()\n",
    "        std_eda = x['EDA'].std()\n",
    "        max_eda = x['EDA'].max()\n",
    "        min_eda = x['EDA'].min()\n",
    "        dr_eda = max_eda/min_eda\n",
    "        peaks,properties = find_peaks(x['EDA'],height = 0)\n",
    "        mn_scr = np.mean(properties['peak_heights'])\n",
    "        std_scr = np.std(properties['peak_heights'])   \n",
    "        num_scr = np.size(peaks)\n",
    "        sum_scr = np.sum(properties['peak_heights'])\n",
    "        width_scr = peak_widths(x['EDA'], peaks, rel_height=0)\n",
    "        ht_scr = properties['peak_heights']\n",
    "        ar_scr = 0.5*np.matmul(ht_scr,width_scr[1])\n",
    "        df_new = df_new.append({'class':classes,'mean_accx':mn_acc_x,'mean_accy':mn_acc_y,'mean_accz':mn_acc_z,\n",
    "                                'std_accx':std_acc_x,'std_accy':std_acc_y,'std_accz':std_acc_z,\n",
    "                                'integral_accx':itgl_acc_x,'integral_accy':itgl_acc_y,'integral_accz':itgl_acc_z,\n",
    "                                'mean_emg':mn_emg,'std_emg':std_emg,'drange_emg':dr_emg,'integral_emg':itgl_emg,\n",
    "                                'median_emg':med_emg,'percentile_10_emg':per_10_emg,'percentile_90_emg':per_90_emg,\n",
    "                                'number_peaks':peaks.size,'mean_peak_amplitudes':mn_pk_amp,'std_peak_amplitude':std_pk_amp,\n",
    "                                'sum_peak_amplitude':sum_pk_amp,'mean_temp':mn_temp,'std_temp':std_temp,'drange_temp':dr_temp,\n",
    "                                'max_temp':max_temp,'min_temp':min_temp,'mean_eda':mn_eda,'std_eda':std_eda,\n",
    "                                'max_eda':max_eda,'min_eda':min_eda,'drange_eda':dr_eda,'mean_scr_peaks':mn_scr,\n",
    "                                'std_scr_peaks':std_scr,'total_scr_peaks':num_scr,'sum_scr_peaks':sum_scr,\n",
    "                                'area_peaks_scr':ar_scr},ignore_index = True)\n",
    "    return(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Data Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect(file_name):\n",
    "    df = pd.read_pickle(os.path.abspath(file_name))\n",
    "    df_labels = df['label']\n",
    "    df_labels = np.reshape(df_labels,(len(df['label']),1))\n",
    "    data = np.concatenate((df['signal']['chest']['ACC'],df['signal']['chest']['ECG'],df['signal']['chest']['EMG'],df['signal']['chest']['EDA'],df['signal']['chest']['Temp'],df['signal']['chest']['Resp'],df_labels),axis = 1)\n",
    "    data = np.array([data[i] for i in range(len(data[:,8])) if 4 >= data[i,8] > 0 ])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reshape the Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_list (size_column_train, size_column_test, width, height, channel, X_train, X_val):\n",
    "    X_train = np.reshape(X_train, (size_column_train, 1, width, height, channel))\n",
    "    X_val = np.reshape(X_val, (size_column_test, 1, width, height, channel))\n",
    "    \n",
    "    return(X_train, X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Create the Model - Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds First Layer - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_first_layer(model, image_size):\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=image_size, padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Second Layer - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_second_layer(model):\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same' ))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Third Layer - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_third_layer(model):\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Last Layer - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense part\n",
    "def CNN_last_layer(model, activation):\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(number_of_classes, activation=activation))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds First Layer - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "def RNN_first_layer(model, first_model, image_size):\n",
    "    model.add(TimeDistributed(first_model))\n",
    "    model.add(LSTM(512, return_sequences=True, input_shape=image_size))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Second Layer - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_second_layer(model):\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Third Layer - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_third_layer(model):\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Adds Last Layer - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_last_layer(model, number_of_classes, activation):\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(number_of_classes, activation=activation))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H4>Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_model(model, X_train, Y_train, X_val, Y_val, batch_size, epochs, optimizer):\n",
    "    print(\"---------------------------------------------\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath=\"Deep_Learning_Model/\" + optimizer + \"_{epoch:02d}.hdf5\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.1, min_delta=0.0001, patience=5, verbose=1)\n",
    "    history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), verbose=1, shuffle=False, callbacks=[checkpointer, lr_reduce])\n",
    "    #model = load_model('BeWell_DL_model.h5')\n",
    "    print(\"---------------------------------------------\")\n",
    "    #model.save('BeWell_DL_model.h5')\n",
    "    \n",
    "    predictions = model.predict(X_val)\n",
    "    score = accuracy_score(change(Y_val), change(predictions))\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Score: \" + str(score))\n",
    "    print(\"---------------------------------------------\")\n",
    "    model_evalutation(history, X_val, Y_val, model)\n",
    "    print(\"---------------------------------------------\")\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(x): \n",
    "    answer = np.zeros((np.shape(x)[0]))\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        max_value = max(x[i, :])\n",
    "        max_index = list(x[i, :]).index(max_value)\n",
    "        answer[i] = max_index\n",
    "    return answer.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evalutation(history, X_val, Y_val, model):\n",
    "    score = model.evaluate((X_val),Y_val)\n",
    "    print(\"Model Accuracy: %.2f%%\" % (score[1]*100))\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper right')\n",
    "\n",
    "    plt.suptitle(\"Model Accuracy and Model Loss\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Calling Functions and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array([])\n",
    "\n",
    "for i in range(start_participant, final_participant):\n",
    "    file_name = path + '/S'+str(i) + '/S'+str(i)+'.pkl'\n",
    "    if (i == 2) :\n",
    "        dataset = data_collect(file_name)\n",
    "    elif (i == 12) :\n",
    "    elif (i >= 3 & i <= 17) :\n",
    "        dataset = np.concatenate((dataset,data_collect(file_name)),axis=0)\n",
    "    #else :\n",
    "        #if i != 12 :\n",
    "            #dataset = np.concatenate((dataset,data_collect(file_name)),axis = 0)\n",
    "            \n",
    "df = pd.DataFrame({'ACC_X':dataset[:,0],'ACC_Y':dataset[:,1],'ACC_Z':dataset[:,2],'ECG':dataset[:,3],'EDA':dataset[:,4],'EMG':dataset[:,5],'RESP':dataset[:,6],'TEMP':dataset[:,7],'TARGET':dataset[:,8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Baseline: 11501002\n",
      "Size Stress: 6470101\n"
     ]
    }
   ],
   "source": [
    "baseline_df = pd.DataFrame(columns = ['ACC_X','ACC_Y','ACC_Z','ECG','EDA','EMG','RESP','TEMP','TARGET'])\n",
    "baseline_df = df.loc[df['TARGET'] == 1.0].copy()\n",
    "baseline_df = baseline_df.reset_index()\n",
    "print(\"Size Baseline: \" + str(len(baseline_df)))\n",
    "\n",
    "if (number_of_classes >= 2):\n",
    "    stress_df = pd.DataFrame(columns = ['ACC_X','ACC_Y','ACC_Z','ECG','EDA','EMG','RESP','TEMP','TARGET'])\n",
    "    stress_df = df.loc[df['TARGET'] == 2.0].copy()\n",
    "    stress_df = stress_df.reset_index()\n",
    "    print(\"Size Stress: \" + str(len(stress_df)))\n",
    "\n",
    "if (number_of_classes >= 3):\n",
    "    amusement_df = pd.DataFrame(columns = ['ACC_X','ACC_Y','ACC_Z','ECG','EDA','EMG','RESP','TEMP','TARGET'])\n",
    "    amusement_df = df.loc[df['TARGET'] == 3.0].copy()\n",
    "    amusement_df = amusement_df.reset_index()\n",
    "    print(\"Size Amusement: \" + str(len(amusement_df)))\n",
    "    \n",
    "if (number_of_classes >= 4):\n",
    "    meditation_df = pd.DataFrame(columns = ['ACC_X','ACC_Y','ACC_Z','ECG','EDA','EMG','RESP','TEMP','TARGET'])\n",
    "    meditation_df = df.loc[df['TARGET'] == 4.0].copy()\n",
    "    meditation_df = meditation_df.reset_index()\n",
    "    print(\"Size Meditation: \" + str(len(meditation_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-03a11780cc0f>:55: PeakPropertyWarning: some peaks have a width of 0\n",
      "  width_scr = peak_widths(x['EDA'], peaks, rel_height=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Baseline: 16430\n",
      "Size Stress: 9243\n"
     ]
    }
   ],
   "source": [
    "baseline_df = feature_extraction(baseline_df, 1)\n",
    "print(\"Size Baseline: \" + str(len(baseline_df)))\n",
    "baseline_df = baseline_df[:16000]\n",
    "\n",
    "if (number_of_classes >= 2):\n",
    "    stress_df = feature_extraction(stress_df, 2)\n",
    "    print(\"Size Stress: \" + str(len(stress_df)))\n",
    "    stress_df = stress_df[:8000]\n",
    "\n",
    "if (number_of_classes >= 3):\n",
    "    amusement_df = feature_extraction(amusement_df, 3)\n",
    "    print(\"Size Amusement: \" + str(len(amusement_df)))\n",
    "    amusement_df = amusement_df[:4000]\n",
    "\n",
    "if (number_of_classes >= 4):\n",
    "    meditation_df = feature_extraction(meditation_df, 4)\n",
    "    print(\"Size Meditation: \" + str(len(meditation_df)))\n",
    "    meditation_df = meditation_df[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Dataset: (24000, 35)\n",
      "Size Dataset: (24000, 1)\n",
      "Size Dataset: (7680, 35)\n",
      "Size Dataset: (7680, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset_x = pd.DataFrame()\n",
    "dataset_x_val = pd.DataFrame()\n",
    "dataset_y_temp = pd.DataFrame(columns = ['class'])\n",
    "dataset_y = pd.DataFrame(columns = ['class'])\n",
    "dataset_y_val = pd.DataFrame(columns = ['class'])\n",
    "\n",
    "\n",
    "dataset_x = dataset_x.append(baseline_df)\n",
    "dataset_y = baseline_df['class']\n",
    "\n",
    "if (number_of_classes >= 2):\n",
    "    dataset_x = dataset_x.append(stress_df)\n",
    "    dataset_y_temp = stress_df['class']\n",
    "    dataset_y = dataset_y.append(dataset_y_temp)\n",
    "    \n",
    "\n",
    "if (number_of_classes >= 3):\n",
    "    dataset_x = dataset_x.append(amusement_df)\n",
    "    dataset_y_temp = amusement_df['class']\n",
    "    dataset_y = dataset_y.append(dataset_y_temp)\n",
    "    \n",
    "if (number_of_classes >= 4):\n",
    "    dataset_x = dataset_x.append(meditation_df)\n",
    "    dataset_y_temp = meditation_df['class']\n",
    "    dataset_y = dataset_y.append(dataset_y_temp)\n",
    "    \n",
    "dataset_x = dataset_x.reset_index()\n",
    "dataset_y = dataset_y.reset_index()\n",
    "dataset_x = dataset_x.drop(['index','class'], axis='columns')\n",
    "dataset_y = dataset_y.drop(['index'], axis='columns')\n",
    "dataset_x_val = dataset_x[10000:15120]\n",
    "dataset_y_val = dataset_y[10000:15120]\n",
    "dataset_x_val = dataset_x_val.append(dataset_x[20000:22560])\n",
    "dataset_y_val = dataset_y_val.append(dataset_y[20000:22560])\n",
    "dataset_x_val = dataset_x_val.append(dataset_x[25000:27510])\n",
    "dataset_y_val = dataset_y_val.append(dataset_y[25000:27510])\n",
    "dataset_x_val = dataset_x_val.append(dataset_x[30000:32510])\n",
    "dataset_y_val = dataset_y_val.append(dataset_y[30000:32510])\n",
    "dataset_x_val = dataset_x_val.reset_index()\n",
    "dataset_y_val = dataset_y_val.reset_index()\n",
    "dataset_x_val = dataset_x_val.drop(['index'], axis='columns')\n",
    "dataset_y_val = dataset_y_val.drop(['index'], axis='columns')\n",
    "\n",
    "print(\"Size Dataset: \" + str(dataset_x.shape))\n",
    "print(\"Size Dataset: \" + str(dataset_y.shape))\n",
    "print(\"Size Dataset: \" + str(dataset_x_val.shape))\n",
    "print(\"Size Dataset: \" + str(dataset_y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = dataset_x.to_numpy()\n",
    "y_train = dataset_y.to_numpy()\n",
    "x_val = dataset_x_val.to_numpy()\n",
    "y_val = dataset_y_val.to_numpy()\n",
    "\n",
    "Y_train = np.zeros((size_column_train, number_of_classes))\n",
    "for i in range(len(Y_train)):\n",
    "    if y_train[i*size_line] == 1:\n",
    "        Y_train[i,0] = 1\n",
    "    elif y_train[i*size_line] == 2:\n",
    "        Y_train[i,1] = 1\n",
    "    elif y_train[i*size_line] == 3:\n",
    "        Y_train[i,2] = 1\n",
    "    else:\n",
    "        Y_train[i,3] = 1\n",
    "        \n",
    "Y_val = np.zeros((size_column_test, number_of_classes))\n",
    "for i in range(len(Y_val)):\n",
    "    if y_train[i*size_line] == 1:\n",
    "        Y_val[i,0] = 1\n",
    "    elif y_train[i*size_line] == 2:\n",
    "        Y_val[i,1] = 1\n",
    "    elif y_train[i*size_line] == 3:\n",
    "        Y_val[i,2] = 1\n",
    "    else:\n",
    "        Y_val[i,3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = reshape_list(size_column_train, size_column_test, width, height, channel, x_train, x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = CNN_first_layer(CNN_model, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = CNN_second_layer(CNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = CNN_third_layer(CNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = CNN_last_layer(CNN_model, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_first_layer(model, CNN_model, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_second_layer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_third_layer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_last_layer(model, number_of_classes, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Epoch 1/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.4700\n",
      "Epoch 00001: val_loss improved from inf to 0.68808, saving model to Deep_Learning_Model/rmsprop_01.hdf5\n",
      "2/2 [==============================] - 2s 998ms/step - loss: 0.6945 - accuracy: 0.4700 - val_loss: 0.6881 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.6700\n",
      "Epoch 00002: val_loss improved from 0.68808 to 0.68439, saving model to Deep_Learning_Model/rmsprop_02.hdf5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6924 - accuracy: 0.6700 - val_loss: 0.6844 - val_accuracy: 1.0000\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6911 - accuracy: 0.6700\n",
      "Epoch 00003: val_loss improved from 0.68439 to 0.68120, saving model to Deep_Learning_Model/rmsprop_03.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6911 - accuracy: 0.6700 - val_loss: 0.6812 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6900 - accuracy: 0.6700\n",
      "Epoch 00004: val_loss improved from 0.68120 to 0.67821, saving model to Deep_Learning_Model/rmsprop_04.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6900 - accuracy: 0.6700 - val_loss: 0.6782 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6890 - accuracy: 0.6700\n",
      "Epoch 00005: val_loss improved from 0.67821 to 0.67531, saving model to Deep_Learning_Model/rmsprop_05.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6890 - accuracy: 0.6700 - val_loss: 0.6753 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6881 - accuracy: 0.6700\n",
      "Epoch 00006: val_loss improved from 0.67531 to 0.67242, saving model to Deep_Learning_Model/rmsprop_06.hdf5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6881 - accuracy: 0.6700 - val_loss: 0.6724 - val_accuracy: 1.0000\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.6700\n",
      "Epoch 00007: val_loss improved from 0.67242 to 0.66953, saving model to Deep_Learning_Model/rmsprop_07.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6872 - accuracy: 0.6700 - val_loss: 0.6695 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.6700\n",
      "Epoch 00008: val_loss improved from 0.66953 to 0.66920, saving model to Deep_Learning_Model/rmsprop_08.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6854 - accuracy: 0.6700 - val_loss: 0.6692 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6853 - accuracy: 0.6700\n",
      "Epoch 00009: val_loss improved from 0.66920 to 0.66890, saving model to Deep_Learning_Model/rmsprop_09.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6853 - accuracy: 0.6700 - val_loss: 0.6689 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.6700\n",
      "Epoch 00010: val_loss improved from 0.66890 to 0.66859, saving model to Deep_Learning_Model/rmsprop_10.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6852 - accuracy: 0.6700 - val_loss: 0.6686 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6851 - accuracy: 0.6700\n",
      "Epoch 00011: val_loss improved from 0.66859 to 0.66830, saving model to Deep_Learning_Model/rmsprop_11.hdf5\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6851 - accuracy: 0.6700 - val_loss: 0.6683 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.6700\n",
      "Epoch 00012: val_loss improved from 0.66830 to 0.66800, saving model to Deep_Learning_Model/rmsprop_12.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6850 - accuracy: 0.6700 - val_loss: 0.6680 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00013: val_loss improved from 0.66800 to 0.66797, saving model to Deep_Learning_Model/rmsprop_13.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6680 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00014: val_loss improved from 0.66797 to 0.66794, saving model to Deep_Learning_Model/rmsprop_14.hdf5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00015: val_loss improved from 0.66794 to 0.66791, saving model to Deep_Learning_Model/rmsprop_15.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00016: val_loss improved from 0.66791 to 0.66789, saving model to Deep_Learning_Model/rmsprop_16.hdf5\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00017: val_loss improved from 0.66789 to 0.66786, saving model to Deep_Learning_Model/rmsprop_17.hdf5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00018: val_loss improved from 0.66786 to 0.66786, saving model to Deep_Learning_Model/rmsprop_18.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00019: val_loss improved from 0.66786 to 0.66785, saving model to Deep_Learning_Model/rmsprop_19.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00020: val_loss improved from 0.66785 to 0.66785, saving model to Deep_Learning_Model/rmsprop_20.hdf5\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00021: val_loss improved from 0.66785 to 0.66785, saving model to Deep_Learning_Model/rmsprop_21.hdf5\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00022: val_loss improved from 0.66785 to 0.66784, saving model to Deep_Learning_Model/rmsprop_22.hdf5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00023: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_23.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00024: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_24.hdf5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00025: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_25.hdf5\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00026: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_26.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00027: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_27.hdf5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00028: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_28.hdf5\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00029: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_29.hdf5\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00030: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00031: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00032: val_loss improved from 0.66784 to 0.66784, saving model to Deep_Learning_Model/rmsprop_32.hdf5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00033: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00034: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00035: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00036: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00037: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00038: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00039: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00040: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00041: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00042: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00043: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00044: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00045: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00046: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00047: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00048: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00049: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00050: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00051: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00052: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00053: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00054: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00055: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00056: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00057: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00058: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00059: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00060: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00061: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00062: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00063: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00064: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00065: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00066: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00067: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00068: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00069: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00070: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00071: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00072: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00073: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00074: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00075: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00076: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00077: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00078: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00079: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00080: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00081: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00082: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00083: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00084: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00085: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00086: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00087: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00088: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00089: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00090: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00091: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00092: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00093: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00094: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00095: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00096: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00097: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00098: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00099: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00100: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00101: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00102: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00103: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00104: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00105: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00106: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00107: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00108: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00109: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00110: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00111: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00112: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00113: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00114: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00115: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00116: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00117: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00118: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00119: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00120: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00121: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00122: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00123: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00124: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00125: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00126: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00127: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00128: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00129: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00130: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00131: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00132: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0000001235416985e-29.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00133: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00134: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00135: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00136: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00137: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1.0000001536343539e-30.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00138: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00139: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00140: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00141: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00142: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 1.000000191250173e-31.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00143: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00144: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00145: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00146: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00147: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.0000002147600601e-32.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00148: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00149: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00150: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00151: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00152: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.0000002441474188e-33.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00153: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00154: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00155: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00156: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00157: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 1.0000002074132203e-34.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00158: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00159: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00160: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00161: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00162: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.0000001614954722e-35.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00163: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00164: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00165: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00166: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00167: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.0000001614954723e-36.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00168: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00169: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00170: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00171: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00172: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00172: ReduceLROnPlateau reducing learning rate to 1.0000001256222317e-37.\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00173: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00174: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00175: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00176: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00177: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.0000001032014561e-38.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00178: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00179: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00180: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00181: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00182: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.0000000751754869e-39.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00183: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00184: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00185: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00186: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00187: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.0000002153053334e-40.\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00188: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00189: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00190: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00191: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00192: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 9.99994610111476e-42.\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00193: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00194: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00195: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00196: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00197: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 9.999665841421895e-43.\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00198: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00199: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00200: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00201: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00202: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 1.0005271035279195e-43.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00203: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00204: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00205: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00206: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00207: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00207: ReduceLROnPlateau reducing learning rate to 9.949219096706202e-45.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00208: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00209: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00210: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00211: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00212: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 9.80908925027372e-46.\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00213: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00214: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00215: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00216: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00217: val_loss did not improve from 0.66784\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.4012984643248171e-46.\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00218: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00219: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00220: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00221: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00222: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00223: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00224: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00225: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00226: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00227: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00228: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00229: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00230: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00231: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00232: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00233: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00234: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00235: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00236: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00237: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00238: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00239: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00240: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00241: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00242: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00243: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00244: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00245: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00246: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00247: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00248: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00249: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00250: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00251: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00252: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00253: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00254: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00255: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00256: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00257: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00258: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00259: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00260: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00261: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00262: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00263: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00264: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00265: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00266: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00267: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00268: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00269: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00270: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00271: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00272: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00273: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00274: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00275: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00276: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00277: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00278: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00279: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00280: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00281: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00282: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00283: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00284: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00285: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00286: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00287: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00288: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00289: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00290: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00291: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00292: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00293: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00294: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00295: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00296: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00297: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00298: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00299: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00300: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00301: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00302: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00303: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00304: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00305: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00306: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00307: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00308: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00309: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00310: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00311: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00312: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00313: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00314: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00315: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00316: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00317: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00318: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00319: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00320: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00321: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00322: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00323: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00324: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00325: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00326: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00327: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00328: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00329: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00330: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00331: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00332: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00333: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00334: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00335: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00336: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00337: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00338: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00339: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00340: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00341: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00342: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00343: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00344: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00345: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00346: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00347: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00348: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00349: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00350: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00351: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00352: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00353: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00354: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00355: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00356: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00357: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00358: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00359: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00360: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00361: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00362: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00363: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00364: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00365: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00366: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00367: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00368: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00369: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00370: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00371: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00372: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00373: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00374: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00375: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00376: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00377: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00378: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00379: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00380: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00381: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00382: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00383: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00384: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00385: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00386: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00387: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00388: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00389: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00390: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00391: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00392: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00393: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00394: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00395: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00396: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00397: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00398: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00399: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00400: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00401: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00402: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00403: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00404: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00405: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00406: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00407: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00408: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00409: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00410: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00411: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00412: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00413: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00414: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00415: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00416: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00417: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00418: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00419: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00420: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00421: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00422: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00423: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00424: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00425: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00426: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00427: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00428: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00429: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00430: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00431: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00432: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00433: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00434: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00435: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00436: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00437: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00438: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00439: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00440: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00441: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00442: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00443: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00444: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00445: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00446: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00447: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00448: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00449: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00450: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00451: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00452: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00453: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00454: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00455: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00456: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00457: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00458: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00459: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00460: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00461: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00462: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00463: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00464: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00465: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00466: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00467: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00468: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00469: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00470: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00471: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00472: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00473: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00474: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00475: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00476: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00477: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00478: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00479: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00480: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00481: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00482: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00483: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00484: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00485: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00486: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00487: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00488: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00489: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00490: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00491: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00492: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00493: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00494: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00495: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00496: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00497: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00498: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00499: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00500: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00501: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00502: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00503: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00504: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00505: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00506: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00507: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00508: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00509: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00510: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00511: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00512: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00513: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00514: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00515: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00516: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00517: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00518: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00519: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00520: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00521: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00522: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00523: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00524: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00525: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00526: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00527: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00528: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00529: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00530: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00531: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00532: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00533: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00534: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00535: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00536: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00537: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00538: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00539: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00540: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00541: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00542: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00543: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00544: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00545: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00546: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00547: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00548: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00549: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00550: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00551: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00552: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00553: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00554: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00555: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00556: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00557: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00558: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00559: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00560: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00561: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00562: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00563: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00564: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00565: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00566: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00567: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00568: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00569: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00570: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00571: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00572: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00573: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00574: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00575: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00576: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00577: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00578: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00579: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00580: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00581: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00582: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00583: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00584: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00585: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00586: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00587: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00588: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00589: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00590: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00591: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00592: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00593: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00594: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00595: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00596: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00597: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00598: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00599: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00600: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00601: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00602: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00603: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00604: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00605: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00606: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00607: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00608: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00609: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00610: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00611: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00612: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00613: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00614: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00615: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00616: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00617: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00618: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00619: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00620: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00621: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00622: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00623: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00624: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00625: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00626: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00627: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00628: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00629: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00630: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00631: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00632: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00633: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00634: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00635: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00636: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00637: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00638: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00639: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00640: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00641: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00642: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00643: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00644: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00645: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00646: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00647: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00648: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00649: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00650: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00651: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00652: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00653: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00654: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00655: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00656: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00657: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00658: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00659: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00660: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00661: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00662: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00663: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00664: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00665: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00666: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00667: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00668: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00669: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00670: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00671: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00672: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00673: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00674: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00675: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00676: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00677: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00678: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00679: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00680: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00681: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00682: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00683: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00684: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00685: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00686: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00687: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00688: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00689: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00690: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00691: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00692: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00693: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00694: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00695: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00696: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00697: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00698: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00699: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00700: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00701: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00702: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00703: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00704: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00705: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00706: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00707: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00708: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00709: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00710: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00711: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00712: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00713: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00714: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00715: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00716: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00717: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00718: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00719: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00720: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00721: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00722: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00723: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00724: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00725: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00726: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00727: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00728: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00729: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00730: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00731: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00732: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00733: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00734: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00735: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00736: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00737: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00738: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00739: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00740: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00741: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00742: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00743: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00744: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00745: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00746: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00747: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00748: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00749: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00750: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00751: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00752: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00753: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00754: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00755: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00756: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00757: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00758: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00759: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00760: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00761: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00762: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00763: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00764: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00765: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00766: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00767: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00768: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00769: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00770: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00771: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00772: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00773: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00774: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00775: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00776: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00777: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00778: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00779: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00780: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00781: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00782: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00783: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00784: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00785: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00786: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00787: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00788: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00789: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00790: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00791: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00792: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00793: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00794: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00795: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00796: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00797: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00798: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00799: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00800: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00801: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00802: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00803: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00804: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00805: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00806: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00807: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00808: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00809: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00810: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00811: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00812: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00813: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00814: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00815: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00816: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00817: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00818: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00819: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00820: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00821: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00822: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00823: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00824: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00825: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00826: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00827: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00828: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00829: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00830: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00831: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00832: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00833: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00834: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00835: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00836: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00837: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00838: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00839: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00840: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00841: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00842: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00843: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00844: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00845: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00846: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00847: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00848: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00849: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00850: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00851: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00852: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00853: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00854: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00855: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00856: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00857: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00858: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00859: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00860: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00861: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00862: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00863: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00864: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00865: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00866: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00867: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00868: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00869: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00870: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00871: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00872: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00873: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00874: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00875: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00876: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00877: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00878: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00879: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00880: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00881: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00882: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00883: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00884: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00885: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00886: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00887: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00888: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00889: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00890: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00891: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00892: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00893: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00894: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00895: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00896: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00897: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00898: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00899: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00900: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00901: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00902: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00903: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00904: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00905: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00906: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00907: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00908: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00909: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00910: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00911: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00912: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00913: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00914: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00915: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00916: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00917: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00918: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00919: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00920: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00921: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00922: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00923: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00924: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00925: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00926: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00927: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00928: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00929: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00930: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00931: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00932: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00933: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00934: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00935: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00936: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00937: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00938: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00939: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00940: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00941: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00942: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00943: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00944: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00945: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00946: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00947: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00948: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00949: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00950: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00951: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00952: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00953: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00954: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00955: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00956: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00957: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00958: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00959: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00960: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00961: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00962: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00963: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00964: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00965: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00966: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00967: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00968: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00969: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00970: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00971: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00972: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00973: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00974: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00975: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00976: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00977: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00978: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00979: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00980: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00981: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00982: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00983: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00984: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00985: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00986: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00987: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00988: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00989: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00990: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00991: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00992: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00993: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00994: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00995: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00996: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00997: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00998: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 00999: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6848 - accuracy: 0.6700\n",
      "Epoch 01000: val_loss did not improve from 0.66784\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.6848 - accuracy: 0.6700 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Score: 1.0\n",
      "---------------------------------------------\n",
      "1/1 [==============================] - 0s 858us/step - loss: 0.6678 - accuracy: 1.0000\n",
      "Model Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#model = train_the_model(model, X_train, Y_train, X_val, Y_val, batch_size, epochs, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
